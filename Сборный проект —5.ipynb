{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "CUQuYmMs-mKK",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CUQuYmMs-mKK",
    "tags": [
     "21a32eca-7494-4096-b202-21be1b7f0a7d"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff1020a",
   "metadata": {
    "cellId": "pbwq209p45adtxfy5ofecd",
    "execution_id": "7cb94123-6481-41de-973a-91abe63db303",
    "id": "1ff1020a"
   },
   "source": [
    "# Прекод\n",
    "\n",
    "# Сборный проект-5\n",
    "\n",
    "Вам поручено разработать демонстрационную версию поиска изображений по запросу.\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные доступны по [ссылке](https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip).\n",
    "\n",
    "В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2dad3c3-65ed-40ee-87fa-b756665e3cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/iuser24/anaconda3/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: torch==2.4.1 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: numpy in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: fsspec in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2.20.5)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (3.0.0)\n",
      "Requirement already satisfied: networkx in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2.5)\n",
      "Requirement already satisfied: jinja2 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: sympy in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (1.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: filelock in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (3.0.12)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from jinja2->torch==2.4.1->torchvision) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from networkx->torch==2.4.1->torchvision) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from sympy->torch==2.4.1->torchvision) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b356cf0-4c88-4642-90e7-1569053d1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29c7f64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99489b26",
   "metadata": {
    "cellId": "n6vkjcacwu39w29bfocxt",
    "execution_id": "1b731a18-3394-4b62-b3f7-018692c2d6de",
    "id": "99489b26"
   },
   "source": [
    "## 1. Исследовательский анализ данных\n",
    "\n",
    "Наш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n",
    "\n",
    "Вы можете воспользоваться другим методом агрегации оценок или придумать свой.\n",
    "\n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке:\n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "После анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n",
    "\n",
    "Ваша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d946021-0965-4ca4-9012-86cd01a1d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_information(df):\n",
    "    display(df.info())\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c14a3631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image       5822 non-null   object\n",
      " 1   query_id    5822 non-null   object\n",
      " 2   query_text  5822 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 136.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262583859_653f1469a9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2447284966_d6bbdb4b6e.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2549968784_39bfbe44f9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2621415349_ef1a7e73be.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "1  1262583859_653f1469a9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "2  2447284966_d6bbdb4b6e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "3  2549968784_39bfbe44f9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "4  2621415349_ef1a7e73be.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "\n",
       "                                          query_text  \n",
       "0  A young child is wearing blue goggles and sitt...  \n",
       "1  A young child is wearing blue goggles and sitt...  \n",
       "2  A young child is wearing blue goggles and sitt...  \n",
       "3  A young child is wearing blue goggles and sitt...  \n",
       "4  A young child is wearing blue goggles and sitt...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"sp5/train_dataset.csv\")\n",
    "primary_information(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79250670",
   "metadata": {
    "cellId": "exl6m83oldxqlu1vq1s6",
    "id": "79250670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47830 entries, 0 to 47829\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   filename              47830 non-null  object \n",
      " 1   description_id        47830 non-null  object \n",
      " 2   confirmed_percentage  47830 non-null  float64\n",
      " 3   confirmed_qty         47830 non-null  int64  \n",
      " 4   disconfirmed_qty      47830 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1056338697_4f7d7ce270.jpg#2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>114051287_dd85625a04.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1427391496_ea512cbe7f.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2073964624_52da3a0fc4.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2083434441_a93bc6306b.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2   \n",
       "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2   \n",
       "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2   \n",
       "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2   \n",
       "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2   \n",
       "\n",
       "   confirmed_percentage  confirmed_qty  disconfirmed_qty  \n",
       "0                   1.0              3                 0  \n",
       "1                   0.0              0                 3  \n",
       "2                   0.0              0                 3  \n",
       "3                   0.0              0                 3  \n",
       "4                   0.0              0                 3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crowd_df = pd.read_csv(\"sp5/CrowdAnnotations.tsv\", sep=\"\\t\", names=[\n",
    "    \"filename\", \"description_id\", \"confirmed_percentage\", \"confirmed_qty\", \"disconfirmed_qty\"\n",
    "])\n",
    "primary_information(crowd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5136f1-37ba-41e9-81a8-c7a0e356eee7",
   "metadata": {},
   "source": [
    "Файл с краудсорсинговыми оценками содержит 47830 строк, пропущенных значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "900a0503-85a4-49a9-b815-a85157408cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   filename        5822 non-null   object\n",
      " 1   description_id  5822 non-null   object\n",
      " 2   exp1            5822 non-null   int64 \n",
      " 3   exp2            5822 non-null   int64 \n",
      " 4   exp3            5822 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 227.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  exp1  exp2  exp3\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2     1     1     1\n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2     1     1     2\n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2     1     1     2\n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2     1     2     2\n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2     1     1     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expert_df = pd.read_csv(\"sp5/ExpertAnnotations.tsv\", sep=\"\\t\", names=[\n",
    "    \"filename\", \"description_id\", \"exp1\", \"exp2\", \"exp3\"\n",
    "])\n",
    "primary_information(expert_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec0ec5-b6c4-4ccc-a9c8-5c1f3d56582a",
   "metadata": {},
   "source": [
    "Файл с экспертными оценками содержит 5822 строки, пропущенных значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b444fb7-2716-4ad4-8a74-603edfc47dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5822 entries, 0 to 5821\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   filename              5822 non-null   object \n",
      " 1   description_id        5822 non-null   object \n",
      " 2   exp1                  5822 non-null   int64  \n",
      " 3   exp2                  5822 non-null   int64  \n",
      " 4   exp3                  5822 non-null   int64  \n",
      " 5   confirmed_percentage  2329 non-null   float64\n",
      " 6   confirmed_qty         2329 non-null   float64\n",
      " 7   disconfirmed_qty      2329 non-null   float64\n",
      "dtypes: float64(3), int64(3), object(2)\n",
      "memory usage: 409.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  exp1  exp2  exp3  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2     1     1     1   \n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2     1     1     2   \n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2     1     1     2   \n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2     1     2     2   \n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2     1     1     2   \n",
       "\n",
       "   confirmed_percentage  confirmed_qty  disconfirmed_qty  \n",
       "0                   0.0            0.0               3.0  \n",
       "1                   0.0            0.0               3.0  \n",
       "2                   NaN            NaN               NaN  \n",
       "3                   NaN            NaN               NaN  \n",
       "4                   NaN            NaN               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations_df = pd.merge(\n",
    "    left=expert_df, \n",
    "    right=crowd_df,\n",
    "    how='left',\n",
    "    left_on=['filename', 'description_id'],\n",
    "    right_on=['filename', 'description_id'],\n",
    ")\n",
    "primary_information(annotations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fb486",
   "metadata": {},
   "source": [
    "Сделали левое объединение, получили 5822 строки. Если делать внутренние объединение, записей будет очень мало, а если внешние, то придется опираться на краудсорсинговые оценки, которые достаточно низкого качества. Поэтому левое объединение считаю наиболее оптимальным решением. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab54e324-e275-411a-aeab-70a172af5e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5817</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2981702521_2459f2c1c4.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5818</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2985679744_75a7102aab.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5819</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3150742439_b8a352e1e0.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5820</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3375070563_3c290a7991.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5821</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>486917990_72bd4069af.jpg#2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5822 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename               description_id  exp1  exp2  \\\n",
       "0     1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2     1     1   \n",
       "1     1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2     1     1   \n",
       "2     1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2     1     1   \n",
       "3     1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2     1     2   \n",
       "4     1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2     1     1   \n",
       "...                         ...                          ...   ...   ...   \n",
       "5817   997722733_0cb5439472.jpg  2981702521_2459f2c1c4.jpg#2     1     1   \n",
       "5818   997722733_0cb5439472.jpg  2985679744_75a7102aab.jpg#2     1     1   \n",
       "5819   997722733_0cb5439472.jpg  3150742439_b8a352e1e0.jpg#2     1     1   \n",
       "5820   997722733_0cb5439472.jpg  3375070563_3c290a7991.jpg#2     1     1   \n",
       "5821   997722733_0cb5439472.jpg   486917990_72bd4069af.jpg#2     3     3   \n",
       "\n",
       "      exp3  confirmed_percentage  confirmed_qty  disconfirmed_qty  \n",
       "0        1              0.000000            0.0               3.0  \n",
       "1        2              0.000000            0.0               3.0  \n",
       "2        2                   NaN            NaN               NaN  \n",
       "3        2                   NaN            NaN               NaN  \n",
       "4        2                   NaN            NaN               NaN  \n",
       "...    ...                   ...            ...               ...  \n",
       "5817     1                   NaN            NaN               NaN  \n",
       "5818     1              0.000000            0.0               3.0  \n",
       "5819     2              0.000000            0.0               3.0  \n",
       "5820     1                   NaN            NaN               NaN  \n",
       "5821     3              0.333333            1.0               2.0  \n",
       "\n",
       "[5822 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca9d8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_calc(x):\n",
    "    vals = [x['exp1'], x['exp2'], x['exp3']]\n",
    "    diff = abs(sum(vals) - min(vals) - max(vals) - sum(vals) / 3.)\n",
    "    if diff < 0.5:\n",
    "        if math.isnan(x['confirmed_percentage']):\n",
    "            return (sum(vals) / 3. - 1) / 3.\n",
    "        else:\n",
    "            return x['confirmed_percentage'] * 0.4 + (sum(vals) / 3. - 1) / 3. * 0.6\n",
    "    if x['confirmed_percentage'] in [0, 1]: \n",
    "        return x['confirmed_percentage']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b715aa",
   "metadata": {},
   "source": [
    "С помощью функции `target_calc` посчитаем целевой признак, с учетом оценок экспертов и крауда в соотношении 3:2. Если мнения экспертов существенно разошлись, то в качестве таргета возьмем оценку крауда, но если только эта оценка единогласная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bafa304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df['target'] = annotations_df.apply(target_calc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3efe82",
   "metadata": {},
   "source": [
    "Посмотрим записи, которым неудалось присвоить таргет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1bcb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1584315962_5b0b45d02d.jpg</td>\n",
       "      <td>3494394662_3edfd4a34c.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>2445283938_ff477c7952.jpg</td>\n",
       "      <td>3280052365_c4644bf0a5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>2529116152_4331dabf50.jpg</td>\n",
       "      <td>3187395715_f2940c2b72.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2735558076_0d7bbc18fc.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>2862004252_53894bb28b.jpg</td>\n",
       "      <td>1267711451_e2a754b4f8.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>2866254827_9a8f592017.jpg</td>\n",
       "      <td>2533424347_cf2f84872b.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>2945036454_280fa5b29f.jpg</td>\n",
       "      <td>3613800013_5a54968ab0.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>300314926_0b2e4b64f5.jpg</td>\n",
       "      <td>3214885227_2be09e7cfb.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>3015863181_92ff43f4d8.jpg</td>\n",
       "      <td>2861932486_52befd8592.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>3107513635_fe8a21f148.jpg</td>\n",
       "      <td>3213992947_3f3f967a9f.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>3109704348_c6416244ce.jpg</td>\n",
       "      <td>2856080862_95d793fa9d.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>3214237686_6566b8b52f.jpg</td>\n",
       "      <td>3255482333_5bcee79f7e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>3245460937_2710a82709.jpg</td>\n",
       "      <td>2470486377_c3a39ccb7b.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>3554634863_5f6f616639.jpg</td>\n",
       "      <td>370713359_7560808550.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>3694093650_547259731e.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>523985664_c866af4850.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>542317719_ed4dd95dc2.jpg</td>\n",
       "      <td>542317719_ed4dd95dc2.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename               description_id  exp1  exp2  \\\n",
       "490   1584315962_5b0b45d02d.jpg  3494394662_3edfd4a34c.jpg#2     1     3   \n",
       "1405  2445283938_ff477c7952.jpg  3280052365_c4644bf0a5.jpg#2     1     1   \n",
       "1667  2529116152_4331dabf50.jpg  3187395715_f2940c2b72.jpg#2     1     1   \n",
       "2122  2735558076_0d7bbc18fc.jpg  1536774449_e16b1b6382.jpg#2     2     4   \n",
       "2336  2862004252_53894bb28b.jpg  1267711451_e2a754b4f8.jpg#2     1     3   \n",
       "2342  2866254827_9a8f592017.jpg  2533424347_cf2f84872b.jpg#2     1     1   \n",
       "2628  2945036454_280fa5b29f.jpg  3613800013_5a54968ab0.jpg#2     1     3   \n",
       "2713   300314926_0b2e4b64f5.jpg  3214885227_2be09e7cfb.jpg#2     1     3   \n",
       "2755  3015863181_92ff43f4d8.jpg  2861932486_52befd8592.jpg#2     1     1   \n",
       "3001  3107513635_fe8a21f148.jpg  3213992947_3f3f967a9f.jpg#2     1     3   \n",
       "3020  3109704348_c6416244ce.jpg  2856080862_95d793fa9d.jpg#2     1     3   \n",
       "3357  3214237686_6566b8b52f.jpg  3255482333_5bcee79f7e.jpg#2     1     3   \n",
       "3534  3245460937_2710a82709.jpg  2470486377_c3a39ccb7b.jpg#2     1     3   \n",
       "4530  3554634863_5f6f616639.jpg   370713359_7560808550.jpg#2     1     1   \n",
       "4922  3694093650_547259731e.jpg  1536774449_e16b1b6382.jpg#2     2     4   \n",
       "5473   523985664_c866af4850.jpg  1536774449_e16b1b6382.jpg#2     2     2   \n",
       "5573   542317719_ed4dd95dc2.jpg   542317719_ed4dd95dc2.jpg#2     1     4   \n",
       "\n",
       "      exp3  confirmed_percentage  confirmed_qty  disconfirmed_qty  target  \n",
       "490      3                   NaN            NaN               NaN     NaN  \n",
       "1405     3                   NaN            NaN               NaN     NaN  \n",
       "1667     3                   NaN            NaN               NaN     NaN  \n",
       "2122     4              0.333333            1.0               2.0     NaN  \n",
       "2336     3              0.333333            1.0               2.0     NaN  \n",
       "2342     3                   NaN            NaN               NaN     NaN  \n",
       "2628     3                   NaN            NaN               NaN     NaN  \n",
       "2713     3                   NaN            NaN               NaN     NaN  \n",
       "2755     3                   NaN            NaN               NaN     NaN  \n",
       "3001     3                   NaN            NaN               NaN     NaN  \n",
       "3020     3              0.666667            2.0               1.0     NaN  \n",
       "3357     3                   NaN            NaN               NaN     NaN  \n",
       "3534     3                   NaN            NaN               NaN     NaN  \n",
       "4530     3                   NaN            NaN               NaN     NaN  \n",
       "4922     4              0.666667            2.0               1.0     NaN  \n",
       "5473     4                   NaN            NaN               NaN     NaN  \n",
       "5573     4              0.666667            2.0               1.0     NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df[annotations_df['target'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a0bba6",
   "metadata": {},
   "source": [
    "Таких записей немного, поэтому можно их удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31d93e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5800</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2981702521_2459f2c1c4.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2985679744_75a7102aab.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5802</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3150742439_b8a352e1e0.jpg#2</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5803</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3375070563_3c290a7991.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5804</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>486917990_72bd4069af.jpg#2</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5805 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename               description_id    target\n",
       "0     1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2  0.000000\n",
       "1     1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2  0.066667\n",
       "2     1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2  0.111111\n",
       "3     1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2  0.222222\n",
       "4     1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2  0.111111\n",
       "...                         ...                          ...       ...\n",
       "5800   997722733_0cb5439472.jpg  2981702521_2459f2c1c4.jpg#2  0.000000\n",
       "5801   997722733_0cb5439472.jpg  2985679744_75a7102aab.jpg#2  0.000000\n",
       "5802   997722733_0cb5439472.jpg  3150742439_b8a352e1e0.jpg#2  0.066667\n",
       "5803   997722733_0cb5439472.jpg  3375070563_3c290a7991.jpg#2  0.000000\n",
       "5804   997722733_0cb5439472.jpg   486917990_72bd4069af.jpg#2  0.533333\n",
       "\n",
       "[5805 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = annotations_df.dropna(subset=['target']).reset_index()[['filename', 'description_id', 'target']]\n",
    "annotations_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbaa861",
   "metadata": {
    "cellId": "9h91oxwx86d7i8rqt5miv4",
    "execution_id": "4401a0e8-fd2b-479b-9e84-6ffafbcead47",
    "id": "7cbaa861"
   },
   "source": [
    "## 2. Проверка данных\n",
    "\n",
    "В некоторых странах, где работает ваша компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    ">\n",
    "\n",
    "Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccec4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "disclaimer_stopwords = ['child', 'boy', 'girl', 'kid', 'kids', 'children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1048d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество записей, попадающих под дисклеймер: 1431\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>799486353_f665d7b0f0.jpg</td>\n",
       "      <td>2170222061_e8bce4a32d.jpg#2</td>\n",
       "      <td>A small animal leaps behind a larger animal , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>799486353_f665d7b0f0.jpg</td>\n",
       "      <td>2196107384_361d73a170.jpg#2</td>\n",
       "      <td>a old man walks down the uncrowded road .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>909808296_23c427022d.jpg</td>\n",
       "      <td>2112921744_92bf706805.jpg#2</td>\n",
       "      <td>A dog stands on the side of a grassy cliff .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>929679367_ff8c7df2ee.jpg</td>\n",
       "      <td>3651971126_309e6a5e22.jpg#2</td>\n",
       "      <td>A blurry photo of two dogs .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>968081289_cdba83ce2e.jpg</td>\n",
       "      <td>2292406847_f366350600.jpg#2</td>\n",
       "      <td>A man rows his boat below .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4391 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image                     query_id  \\\n",
       "0     1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "1     3187395715_f2940c2b72.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "2      463978865_c87c6ca84c.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "3      488590040_35a3e96c89.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "4      534875358_6ea30d3091.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "...                         ...                          ...   \n",
       "4386   799486353_f665d7b0f0.jpg  2170222061_e8bce4a32d.jpg#2   \n",
       "4387   799486353_f665d7b0f0.jpg  2196107384_361d73a170.jpg#2   \n",
       "4388   909808296_23c427022d.jpg  2112921744_92bf706805.jpg#2   \n",
       "4389   929679367_ff8c7df2ee.jpg  3651971126_309e6a5e22.jpg#2   \n",
       "4390   968081289_cdba83ce2e.jpg  2292406847_f366350600.jpg#2   \n",
       "\n",
       "                                             query_text  \n",
       "0       A man sleeps under a blanket on a city street .  \n",
       "1       A man sleeps under a blanket on a city street .  \n",
       "2       A man sleeps under a blanket on a city street .  \n",
       "3       A man sleeps under a blanket on a city street .  \n",
       "4       A man sleeps under a blanket on a city street .  \n",
       "...                                                 ...  \n",
       "4386  A small animal leaps behind a larger animal , ...  \n",
       "4387          a old man walks down the uncrowded road .  \n",
       "4388       A dog stands on the side of a grassy cliff .  \n",
       "4389                       A blurry photo of two dogs .  \n",
       "4390                        A man rows his boat below .  \n",
       "\n",
       "[4391 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = train_df[train_df['query_text'].str.extract(f\"({'|'.join(disclaimer_stopwords)})\").notna()[0]].index\n",
    "print(f\"Количество записей, попадающих под дисклеймер: {len(idx)}\")\n",
    "train_df = train_df.drop(idx).reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352d2cd",
   "metadata": {
    "cellId": "6j23jr8qr9wgyyqkm2puj",
    "id": "b352d2cd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d4ef807",
   "metadata": {
    "cellId": "ggxcvhmhcm9rshysbjoo4n",
    "execution_id": "d7935f99-48c0-42b8-a227-dd2b2d9b70fc",
    "id": "1d4ef807"
   },
   "source": [
    "## 3. Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений.\n",
    "\n",
    "Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют \"выделить\" главные компоненты изображений. Как это сделать? Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb18b2e3-c8cf-4392-8663-e6ac16fc4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_PATH = 'sp5/train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0167b804",
   "metadata": {
    "cellId": "4wiflhqkew9mq1gq5927e",
    "id": "0167b804"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iuser24/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/iuser24/anaconda3/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True) #загружаем претренированную модель\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8cf7fb4-f519-4a97-af82-97a49cef62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(resnet.children())[:-2]\n",
    "resnet = nn.Sequential(*modules) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f31fbbee-5dce-4195-9dae-fbd35ba3733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9778643-32b8-494e-9785-de9412818874",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "258ecc2e-81a3-445a-beb9-3368119000ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"sp5/train_images/488590040_35a3e96c89.jpg\").convert('RGB')\n",
    "input_tensor = preprocess(img)\n",
    "output_tensor = resnet(input_tensor.unsqueeze(0)).flatten() # сразу спрямим тензор в вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "734b5378-3927-4425-b3db-271fb209916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(x):\n",
    "    img = Image.open(f\"{TRAIN_IMG_PATH}/{x}\").convert('RGB')\n",
    "    return resnet(preprocess(img).unsqueeze(0)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2879b425-a2a8-4b43-a132-96a06c7ca7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a3945e106148bd8796729cef032421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['image_embeddings'] = train_df['image'].progress_apply(create_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea53bf6",
   "metadata": {
    "cellId": "z8evfugfch8wpstvnxv0t",
    "execution_id": "028ade1d-49fe-4110-8b13-3c1aecdaa142",
    "id": "aea53bf6"
   },
   "source": [
    "## 4. Векторизация текстов\n",
    "\n",
    "Следующий этап — векторизация текстов. Вы можете поэкспериментировать с несколькими способами векторизации текстов:\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- \\*трансформеры (например Bert)\n",
    "\n",
    "\\* — если вы изучали трансформеры в спринте Машинное обучение для текстов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd7584bd",
   "metadata": {
    "cellId": "5f0eae9yldcozrwh01qp0c",
    "id": "cd7584bd"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2611c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    # Переведем текст в нижний регистр\n",
    "    text = text.lower()\n",
    "    # Разложим на токены\n",
    "    tokens = word_tokenize(text)\n",
    "    # Приведем к каждому токену часть речи\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Произведем лемматизацию в соответствии с частью речи\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(token, get_wordnet_pos(pos)) for token, pos in pos_tags\n",
    "    ]\n",
    "    # Очистим текст от цифр и знаков препинания\n",
    "    cleared_text = clear_text(\" \".join(lemmatized_tokens))\n",
    "    return cleared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38e6be13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac427dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    clr_txt = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clr_txt_list = clr_txt.split() \n",
    "    return ' '.join(clr_txt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737a9f59",
   "metadata": {},
   "source": [
    "Произведем обработку текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d39a03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70cce9edcb924fbaa5c07291eaf74bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['lemm_text'] = train_df['query_text'].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcbb2482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a man sleep under a blanket on a city street\n",
       "1    a man sleep under a blanket on a city street\n",
       "2    a man sleep under a blanket on a city street\n",
       "3    a man sleep under a blanket on a city street\n",
       "4    a man sleep under a blanket on a city street\n",
       "Name: lemm_text, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['lemm_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7446d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим исходный стобец\n",
    "train_df = train_df.drop(['query_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bcd7e66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/iuser24/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = list(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34281263",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "train_df['tf_idf'] = count_tf_idf.fit_transform(train_df['lemm_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a858745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>image_embeddings</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>[tensor(0.), tensor(0.4254), tensor(0.), tenso...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.0370), tenso...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "1  3187395715_f2940c2b72.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "2   463978865_c87c6ca84c.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "3   488590040_35a3e96c89.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "4   534875358_6ea30d3091.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "\n",
       "                                    image_embeddings  \\\n",
       "0  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "1  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "2  [tensor(0.), tensor(0.4254), tensor(0.), tenso...   \n",
       "3  [tensor(0.), tensor(0.), tensor(0.0370), tenso...   \n",
       "4  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "\n",
       "                                      lemm_text  \\\n",
       "0  a man sleep under a blanket on a city street   \n",
       "1  a man sleep under a blanket on a city street   \n",
       "2  a man sleep under a blanket on a city street   \n",
       "3  a man sleep under a blanket on a city street   \n",
       "4  a man sleep under a blanket on a city street   \n",
       "\n",
       "                                              tf_idf  \n",
       "0    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  \n",
       "1    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  \n",
       "2    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  \n",
       "3    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  \n",
       "4    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f0d14ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4391x991 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 25754 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[3]['tf_idf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c0ccd",
   "metadata": {
    "cellId": "yci1zcmnsacl720fr75sb",
    "execution_id": "5ecfa9d5-3913-4fb3-a33e-99bab3798577",
    "id": "760c0ccd"
   },
   "source": [
    "## 5. Объединение векторов\n",
    "\n",
    "Подготовьте данные для обучения: объедините векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b747671f",
   "metadata": {
    "cellId": "n64cmotqegij9arvbc7sxf",
    "id": "b747671f"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    left=train_df[['image', 'query_id', 'image_embeddings', 'tf_idf']], \n",
    "    right=annotations_df[['filename', 'description_id', 'target']],\n",
    "    how='inner',\n",
    "    left_on=['image', 'query_id'],\n",
    "    right_on=['filename', 'description_id'],\n",
    ")[['image', 'image_embeddings', 'tf_idf', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d50da4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4377 entries, 0 to 4376\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image             4377 non-null   object \n",
      " 1   image_embeddings  4377 non-null   object \n",
      " 2   tf_idf            4377 non-null   object \n",
      " 3   target            4377 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 171.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_embeddings</th>\n",
       "      <th>tf_idf</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.4254), tensor(0.), tenso...</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.0370), tenso...</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1056338697_4f7d7ce270.jpg   \n",
       "1  3187395715_f2940c2b72.jpg   \n",
       "2   463978865_c87c6ca84c.jpg   \n",
       "3   488590040_35a3e96c89.jpg   \n",
       "4   534875358_6ea30d3091.jpg   \n",
       "\n",
       "                                    image_embeddings  \\\n",
       "0  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "1  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "2  [tensor(0.), tensor(0.4254), tensor(0.), tenso...   \n",
       "3  [tensor(0.), tensor(0.), tensor(0.0370), tenso...   \n",
       "4  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "\n",
       "                                              tf_idf    target  \n",
       "0    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  0.111111  \n",
       "1    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  0.222222  \n",
       "2    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  0.200000  \n",
       "3    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  0.222222  \n",
       "4    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...  0.111111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "primary_information(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc5668",
   "metadata": {
    "cellId": "97c9jj3s2zjj62vznivsk",
    "execution_id": "1a2d7233-0c79-479a-be63-5787145e3b48",
    "id": "60bc5668"
   },
   "source": [
    "## 6. Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n",
    "Для того чтобы учесть изображения при разбиении, можно воспользоваться классом [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) из библиотеки sklearn.model_selection.\n",
    "\n",
    "Код ниже разбивает датасет на тренировочную и тестовую выборки в пропорции 7:3 так, что строки с одинаковым значением 'group_column' будут содержаться либо в тестовом, либо в тренировочном датасете.\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['group_column']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "```\n",
    "\n",
    "Какую модель использовать — выберите самостоятельно. Также вам предстоит выбрать метрику качества либо реализовать свою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a723a8ad",
   "metadata": {
    "cellId": "v1ntb27jt4z9fazi1y8me",
    "id": "a723a8ad"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['image']))\n",
    "train_df, test_df = df.loc[train_indices][['image_embeddings', 'tf_idf', 'target']], df.loc[test_indices][['image_embeddings', 'tf_idf', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03a146a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3057, 3), (1320, 3))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7f80ab27",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "49b8a510",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b52e6b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tf_idf\n",
       "0    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...\n",
       "2    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...\n",
       "3    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...\n",
       "5    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0...\n",
       "6    (0, 835)\\t0.33154477942249244\\n  (0, 156)\\t0..."
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop(['target', 'image_embeddings'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fcd9d348",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'csr_matrix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-b6263a871c50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 )\n\u001b[1;32m   1150\u001b[0m             ):\n\u001b[0;32m-> 1151\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1205\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         )\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1148\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m     def __array_wrap__(\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "model.fit(train_df.drop(['target', 'image_embeddings'], axis=1), train_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f870d77",
   "metadata": {
    "cellId": "tbnfwg686jpxjdsw7cqbl",
    "execution_id": "5e14c3be-a481-438e-a979-0f4621acea44",
    "id": "2f870d77"
   },
   "source": [
    "## 7. Тестирование модели\n",
    "\n",
    "Настало время протестировать модель. Для этого получите эмбеддинги для всех тестовых изображений из папки `test_images`, выберите случайные 10 запросов из файла `test_queries.csv` и для каждого запроса выведите наиболее релевантное изображение. Сравните визуально качество поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc29a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMG_PATH = 'sp5/train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e0c32",
   "metadata": {
    "cellId": "q6sn9kh039f4a6xvu66y7",
    "id": "801e0c32"
   },
   "outputs": [],
   "source": [
    "test_queries_df = pd.read_csv(\"sp5/test_queries.csv\", sep=\"|\")\n",
    "primary_information(test_queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1345a",
   "metadata": {
    "cellId": "dnvdkzzxdpet1yc4m64cx",
    "execution_id": "3e367f6a-97e3-4ed7-9b73-39ed363fd2b7",
    "id": "fab1345a"
   },
   "source": [
    "## 8. Выводы\n",
    "\n",
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Исследовательский анализ данных выполнен\n",
    "- [ ]  Проверены экспертные оценки и краудсорсинговые оценки\n",
    "- [ ]  Из датасета исключены те объекты, которые выходят за рамки юридических ограничений\n",
    "- [ ]  Изображения векторизованы\n",
    "- [ ]  Текстовые запросы векторизованы\n",
    "- [ ]  Данные корректно разбиты на тренировочную и тестовую выборки\n",
    "- [ ]  Предложена метрика качества работы модели\n",
    "- [ ]  Предложена модель схожести изображений и текстового запроса\n",
    "- [ ]  Модель обучена\n",
    "- [ ]  По итогам обучения модели сделаны выводы\n",
    "- [ ]  Проведено тестирование работы модели\n",
    "- [ ]  По итогам тестирования визуально сравнили качество поиска"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "notebookId": "e47b60f7-b2b4-44ee-beb3-b44a93eaf068",
  "notebookPath": "precode.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
