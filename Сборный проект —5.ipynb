{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "CUQuYmMs-mKK",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CUQuYmMs-mKK",
    "tags": [
     "21a32eca-7494-4096-b202-21be1b7f0a7d"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff1020a",
   "metadata": {
    "cellId": "pbwq209p45adtxfy5ofecd",
    "execution_id": "7cb94123-6481-41de-973a-91abe63db303",
    "id": "1ff1020a"
   },
   "source": [
    "# Прекод\n",
    "\n",
    "# Сборный проект-5\n",
    "\n",
    "Вам поручено разработать демонстрационную версию поиска изображений по запросу.\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные доступны по [ссылке](https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip).\n",
    "\n",
    "В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2dad3c3-65ed-40ee-87fa-b756665e3cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/iuser24/anaconda3/lib/python3.8/site-packages (0.19.1)\n",
      "Requirement already satisfied: numpy in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: torch==2.4.1 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torchvision) (2.4.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torchvision) (8.2.0)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.0.106)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (3.0.0)\n",
      "Requirement already satisfied: filelock in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (3.0.12)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (11.4.5.107)\n",
      "Requirement already satisfied: fsspec in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2.20.5)\n",
      "Requirement already satisfied: networkx in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (2.5)\n",
      "Requirement already satisfied: sympy in /home/iuser24/anaconda3/lib/python3.8/site-packages (from torch==2.4.1->torchvision) (1.8)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.1->torchvision) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from jinja2->torch==2.4.1->torchvision) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from networkx->torch==2.4.1->torchvision) (5.0.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from sympy->torch==2.4.1->torchvision) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b356cf0-4c88-4642-90e7-1569053d1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import requests\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "# импортируем библиотеки для работы с progress bar\n",
    "from tqdm import *\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# импортируем pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# импортируем библиотеки для работы с текстом\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# импортируем класс GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# загружаем нужные модели\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "# import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c180649-4d1f-40a4-9e7e-8a6b78cd657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TORCH_HOME'] = 'models/resnet' #setting the environment variable\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c864fbab-1026-4a26-8c2b-b46268b675fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883957fe",
   "metadata": {},
   "source": [
    "Объявим константы для работы с проектом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5afa8202",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILENAME = \"dsplus_integrated_project_4.zip\"\n",
    "DATA_URL = \"https://code.s3.yandex.net/datasets/\" + DATA_FILENAME\n",
    "DATA_ROOT_FOLDER = \"data/\"\n",
    "TRAIN_IMG_PATH = DATA_ROOT_FOLDER + \"to_upload/train_images\"\n",
    "TEST_IMG_PATH =  DATA_ROOT_FOLDER + \"to_upload/test_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "39be03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filename, path_to_file):\n",
    "  with requests.get(url, stream=True) as r:\n",
    "      r.raise_for_status()\n",
    "      with open(filename, 'wb') as f:\n",
    "          pbar = tqdm(total=int(r.headers['Content-Length']))\n",
    "          for chunk in r.iter_content(chunk_size=8192):\n",
    "              if chunk:\n",
    "                  f.write(chunk)\n",
    "                  pbar.update(len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a7c6237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(path_to_zip_file, directory_to_extract_to):\n",
    "  with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
    "      zip_ref.extractall(directory_to_extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4fa497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613edf0366ef41178e9a4283247b4d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150987455 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "download_file(DATA_URL, DATA_FILENAME, DATA_ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d07e5a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_file(DATA_FILENAME, DATA_ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99489b26",
   "metadata": {
    "cellId": "n6vkjcacwu39w29bfocxt",
    "execution_id": "1b731a18-3394-4b62-b3f7-018692c2d6de",
    "id": "99489b26"
   },
   "source": [
    "## 1. Исследовательский анализ данных\n",
    "\n",
    "Наш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n",
    "\n",
    "Вы можете воспользоваться другим методом агрегации оценок или придумать свой.\n",
    "\n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке:\n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "После анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n",
    "\n",
    "Ваша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2d946021-0965-4ca4-9012-86cd01a1d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_information(df):\n",
    "    display(df.info())\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c14a3631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image       5822 non-null   object\n",
      " 1   query_id    5822 non-null   object\n",
      " 2   query_text  5822 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 136.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262583859_653f1469a9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2447284966_d6bbdb4b6e.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2549968784_39bfbe44f9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2621415349_ef1a7e73be.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "1  1262583859_653f1469a9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "2  2447284966_d6bbdb4b6e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "3  2549968784_39bfbe44f9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "4  2621415349_ef1a7e73be.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "\n",
       "                                          query_text  \n",
       "0  A young child is wearing blue goggles and sitt...  \n",
       "1  A young child is wearing blue goggles and sitt...  \n",
       "2  A young child is wearing blue goggles and sitt...  \n",
       "3  A young child is wearing blue goggles and sitt...  \n",
       "4  A young child is wearing blue goggles and sitt...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(DATA_ROOT_FOLDER + \"to_upload/train_dataset.csv\")\n",
    "primary_information(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "79250670",
   "metadata": {
    "cellId": "exl6m83oldxqlu1vq1s6",
    "id": "79250670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47830 entries, 0 to 47829\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   filename              47830 non-null  object \n",
      " 1   description_id        47830 non-null  object \n",
      " 2   confirmed_percentage  47830 non-null  float64\n",
      " 3   confirmed_qty         47830 non-null  int64  \n",
      " 4   disconfirmed_qty      47830 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1056338697_4f7d7ce270.jpg#2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>114051287_dd85625a04.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1427391496_ea512cbe7f.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2073964624_52da3a0fc4.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2083434441_a93bc6306b.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2   \n",
       "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2   \n",
       "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2   \n",
       "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2   \n",
       "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2   \n",
       "\n",
       "   confirmed_percentage  confirmed_qty  disconfirmed_qty  \n",
       "0                   1.0              3                 0  \n",
       "1                   0.0              0                 3  \n",
       "2                   0.0              0                 3  \n",
       "3                   0.0              0                 3  \n",
       "4                   0.0              0                 3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crowd_df = pd.read_csv(DATA_ROOT_FOLDER + \"to_upload/CrowdAnnotations.tsv\", sep=\"\\t\", names=[\n",
    "    \"filename\", \"description_id\", \"confirmed_percentage\", \"confirmed_qty\", \"disconfirmed_qty\"\n",
    "])\n",
    "primary_information(crowd_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5136f1-37ba-41e9-81a8-c7a0e356eee7",
   "metadata": {},
   "source": [
    "Файл с краудсорсинговыми оценками содержит 47830 строк, пропущенных значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "900a0503-85a4-49a9-b815-a85157408cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   filename        5822 non-null   object\n",
      " 1   description_id  5822 non-null   object\n",
      " 2   exp1            5822 non-null   int64 \n",
      " 3   exp2            5822 non-null   int64 \n",
      " 4   exp3            5822 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 227.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  exp1  exp2  exp3\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2     1     1     1\n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2     1     1     2\n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2     1     1     2\n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2     1     2     2\n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2     1     1     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expert_df = pd.read_csv(DATA_ROOT_FOLDER + \"to_upload/ExpertAnnotations.tsv\", sep=\"\\t\", names=[\n",
    "    \"filename\", \"description_id\", \"exp1\", \"exp2\", \"exp3\"\n",
    "])\n",
    "primary_information(expert_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec0ec5-b6c4-4ccc-a9c8-5c1f3d56582a",
   "metadata": {},
   "source": [
    "Файл с экспертными оценками содержит 5822 строки, пропущенных значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6b444fb7-2716-4ad4-8a74-603edfc47dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   filename              5822 non-null   object \n",
      " 1   description_id        5822 non-null   object \n",
      " 2   exp1                  5822 non-null   int64  \n",
      " 3   exp2                  5822 non-null   int64  \n",
      " 4   exp3                  5822 non-null   int64  \n",
      " 5   confirmed_percentage  2329 non-null   float64\n",
      " 6   confirmed_qty         2329 non-null   float64\n",
      " 7   disconfirmed_qty      2329 non-null   float64\n",
      "dtypes: float64(3), int64(3), object(2)\n",
      "memory usage: 364.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  exp1  exp2  exp3  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2     1     1     1   \n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2     1     1     2   \n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2     1     1     2   \n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2     1     2     2   \n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2     1     1     2   \n",
       "\n",
       "   confirmed_percentage  confirmed_qty  disconfirmed_qty  \n",
       "0                   0.0            0.0               3.0  \n",
       "1                   0.0            0.0               3.0  \n",
       "2                   NaN            NaN               NaN  \n",
       "3                   NaN            NaN               NaN  \n",
       "4                   NaN            NaN               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations_df = pd.merge(\n",
    "    left=expert_df,\n",
    "    right=crowd_df,\n",
    "    how='left',\n",
    "    left_on=['filename', 'description_id'],\n",
    "    right_on=['filename', 'description_id'],\n",
    ")\n",
    "primary_information(annotations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e140b810",
   "metadata": {},
   "source": [
    "Сделали левое объединение, получили 5822 строки. Если делать внутренние объединение, записей будет очень мало, а если внешние, то придется опираться на краудсорсинговые оценки, которые достаточно низкого качества. Поэтому левое объединение считаю наиболее оптимальным решением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ca9d8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_calc(x):\n",
    "    vals = [x['exp1'], x['exp2'], x['exp3']]\n",
    "    diff = abs(sum(vals) - min(vals) - max(vals) - sum(vals) / 3.)\n",
    "    if diff < 0.5:\n",
    "        if math.isnan(x['confirmed_percentage']):\n",
    "            return (sum(vals) / 3. - 1) / 3.\n",
    "        else:\n",
    "            return x['confirmed_percentage'] * 0.4 + (sum(vals) / 3. - 1) / 3. * 0.6\n",
    "    if x['confirmed_percentage'] in [0, 1]:\n",
    "        return x['confirmed_percentage']\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e89542",
   "metadata": {},
   "source": [
    "С помощью функции `target_calc` посчитаем целевой признак, с учетом оценок экспертов и крауда в соотношении 3:2. Если мнения экспертов существенно разошлись, то в качестве таргета возьмем оценку крауда, но только в том случае, если эта оценка единогласная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "bafa304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df['target'] = annotations_df.apply(target_calc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e208580",
   "metadata": {},
   "source": [
    "Посмотрим записи, которым неудалось присвоить таргет:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "07311d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1584315962_5b0b45d02d.jpg</td>\n",
       "      <td>3494394662_3edfd4a34c.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>2445283938_ff477c7952.jpg</td>\n",
       "      <td>3280052365_c4644bf0a5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>2529116152_4331dabf50.jpg</td>\n",
       "      <td>3187395715_f2940c2b72.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>2735558076_0d7bbc18fc.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>2862004252_53894bb28b.jpg</td>\n",
       "      <td>1267711451_e2a754b4f8.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>2866254827_9a8f592017.jpg</td>\n",
       "      <td>2533424347_cf2f84872b.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2628</th>\n",
       "      <td>2945036454_280fa5b29f.jpg</td>\n",
       "      <td>3613800013_5a54968ab0.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>300314926_0b2e4b64f5.jpg</td>\n",
       "      <td>3214885227_2be09e7cfb.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>3015863181_92ff43f4d8.jpg</td>\n",
       "      <td>2861932486_52befd8592.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3001</th>\n",
       "      <td>3107513635_fe8a21f148.jpg</td>\n",
       "      <td>3213992947_3f3f967a9f.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>3109704348_c6416244ce.jpg</td>\n",
       "      <td>2856080862_95d793fa9d.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>3214237686_6566b8b52f.jpg</td>\n",
       "      <td>3255482333_5bcee79f7e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>3245460937_2710a82709.jpg</td>\n",
       "      <td>2470486377_c3a39ccb7b.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>3554634863_5f6f616639.jpg</td>\n",
       "      <td>370713359_7560808550.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>3694093650_547259731e.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>523985664_c866af4850.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>542317719_ed4dd95dc2.jpg</td>\n",
       "      <td>542317719_ed4dd95dc2.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename               description_id  exp1  exp2  \\\n",
       "490   1584315962_5b0b45d02d.jpg  3494394662_3edfd4a34c.jpg#2     1     3   \n",
       "1405  2445283938_ff477c7952.jpg  3280052365_c4644bf0a5.jpg#2     1     1   \n",
       "1667  2529116152_4331dabf50.jpg  3187395715_f2940c2b72.jpg#2     1     1   \n",
       "2122  2735558076_0d7bbc18fc.jpg  1536774449_e16b1b6382.jpg#2     2     4   \n",
       "2336  2862004252_53894bb28b.jpg  1267711451_e2a754b4f8.jpg#2     1     3   \n",
       "2342  2866254827_9a8f592017.jpg  2533424347_cf2f84872b.jpg#2     1     1   \n",
       "2628  2945036454_280fa5b29f.jpg  3613800013_5a54968ab0.jpg#2     1     3   \n",
       "2713   300314926_0b2e4b64f5.jpg  3214885227_2be09e7cfb.jpg#2     1     3   \n",
       "2755  3015863181_92ff43f4d8.jpg  2861932486_52befd8592.jpg#2     1     1   \n",
       "3001  3107513635_fe8a21f148.jpg  3213992947_3f3f967a9f.jpg#2     1     3   \n",
       "3020  3109704348_c6416244ce.jpg  2856080862_95d793fa9d.jpg#2     1     3   \n",
       "3357  3214237686_6566b8b52f.jpg  3255482333_5bcee79f7e.jpg#2     1     3   \n",
       "3534  3245460937_2710a82709.jpg  2470486377_c3a39ccb7b.jpg#2     1     3   \n",
       "4530  3554634863_5f6f616639.jpg   370713359_7560808550.jpg#2     1     1   \n",
       "4922  3694093650_547259731e.jpg  1536774449_e16b1b6382.jpg#2     2     4   \n",
       "5473   523985664_c866af4850.jpg  1536774449_e16b1b6382.jpg#2     2     2   \n",
       "5573   542317719_ed4dd95dc2.jpg   542317719_ed4dd95dc2.jpg#2     1     4   \n",
       "\n",
       "      exp3  confirmed_percentage  confirmed_qty  disconfirmed_qty  target  \n",
       "490      3                   NaN            NaN               NaN     NaN  \n",
       "1405     3                   NaN            NaN               NaN     NaN  \n",
       "1667     3                   NaN            NaN               NaN     NaN  \n",
       "2122     4              0.333333            1.0               2.0     NaN  \n",
       "2336     3              0.333333            1.0               2.0     NaN  \n",
       "2342     3                   NaN            NaN               NaN     NaN  \n",
       "2628     3                   NaN            NaN               NaN     NaN  \n",
       "2713     3                   NaN            NaN               NaN     NaN  \n",
       "2755     3                   NaN            NaN               NaN     NaN  \n",
       "3001     3                   NaN            NaN               NaN     NaN  \n",
       "3020     3              0.666667            2.0               1.0     NaN  \n",
       "3357     3                   NaN            NaN               NaN     NaN  \n",
       "3534     3                   NaN            NaN               NaN     NaN  \n",
       "4530     3                   NaN            NaN               NaN     NaN  \n",
       "4922     4              0.666667            2.0               1.0     NaN  \n",
       "5473     4                   NaN            NaN               NaN     NaN  \n",
       "5573     4              0.666667            2.0               1.0     NaN  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df[annotations_df['target'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d143850",
   "metadata": {},
   "source": [
    "Таких записей немного, поэтому можно их удалить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "9d93c030",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = annotations_df.dropna(subset=['target']).reset_index()[['filename', 'description_id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "34dd0e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations_df['target'].plot(kind='hist', bins=20, title='target')\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbaa861",
   "metadata": {
    "cellId": "9h91oxwx86d7i8rqt5miv4",
    "execution_id": "4401a0e8-fd2b-479b-9e84-6ffafbcead47",
    "id": "7cbaa861"
   },
   "source": [
    "## 2. Проверка данных\n",
    "\n",
    "В некоторых странах, где работает ваша компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    ">\n",
    "\n",
    "Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "ccec4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "disclaimer_stopwords = ['child', 'boy', 'boys', 'girl', 'girls', 'kid', 'kids', 'children', 'baby', 'babies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1048d565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество записей, попадающих под дисклеймер: 1553\n"
     ]
    }
   ],
   "source": [
    "idx = train_df[train_df['query_text'].str.lower().str.extract(f\"({'|'.join(disclaimer_stopwords)})\").notna()[0]].index\n",
    "print(f\"Количество записей, попадающих под дисклеймер: {len(idx)}\")\n",
    "train_df = train_df.drop(idx).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b352d2cd",
   "metadata": {
    "cellId": "6j23jr8qr9wgyyqkm2puj",
    "id": "b352d2cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4269 entries, 0 to 4268\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image       4269 non-null   object\n",
      " 1   query_id    4269 non-null   object\n",
      " 2   query_text  4269 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 100.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "1  3187395715_f2940c2b72.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "2   463978865_c87c6ca84c.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "3   488590040_35a3e96c89.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "4   534875358_6ea30d3091.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "\n",
       "                                        query_text  \n",
       "0  A man sleeps under a blanket on a city street .  \n",
       "1  A man sleeps under a blanket on a city street .  \n",
       "2  A man sleeps under a blanket on a city street .  \n",
       "3  A man sleeps under a blanket on a city street .  \n",
       "4  A man sleeps under a blanket on a city street .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "primary_information(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4ef807",
   "metadata": {
    "cellId": "ggxcvhmhcm9rshysbjoo4n",
    "execution_id": "d7935f99-48c0-42b8-a227-dd2b2d9b70fc",
    "id": "1d4ef807"
   },
   "source": [
    "## 3. Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений.\n",
    "\n",
    "Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют \"выделить\" главные компоненты изображений. Как это сделать? Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "0167b804",
   "metadata": {
    "cellId": "4wiflhqkew9mq1gq5927e",
    "id": "0167b804",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Evgeniy\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Evgeniy\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True) #загружаем претренированную модель\n",
    "if device == 'cuda':\n",
    "    resnet = resnet.cuda()\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "a8cf7fb4-f519-4a97-af82-97a49cef62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(resnet.children())[:-2]\n",
    "resnet = nn.Sequential(*modules) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f31fbbee-5dce-4195-9dae-fbd35ba3733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a9778643-32b8-494e-9785-de9412818874",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "734b5378-3927-4425-b3db-271fb209916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(x):\n",
    "    img = Image.open(f\"{TRAIN_IMG_PATH}/{x}\").convert('RGB')\n",
    "    return resnet(preprocess(img).unsqueeze(0).to(device)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2879b425-a2a8-4b43-a132-96a06c7ca7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de07deb84a7d422ebfac2f686712bebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4269 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 30s\n",
      "Wall time: 53.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['image_embeddings'] = train_df['image'].progress_apply(create_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467ec02-f05d-420f-bd80-d94b67e7cfa9",
   "metadata": {},
   "source": [
    "CPU times: total: 3min 28s\n",
    "Wall time: 52.9 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8419a460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25088"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['image_embeddings'].iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea53bf6",
   "metadata": {
    "cellId": "z8evfugfch8wpstvnxv0t",
    "execution_id": "028ade1d-49fe-4110-8b13-3c1aecdaa142",
    "id": "aea53bf6"
   },
   "source": [
    "## 4. Векторизация текстов\n",
    "\n",
    "Следующий этап — векторизация текстов. Вы можете поэкспериментировать с несколькими способами векторизации текстов:\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- \\*трансформеры (например Bert)\n",
    "\n",
    "\\* — если вы изучали трансформеры в спринте Машинное обучение для текстов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd7584bd",
   "metadata": {
    "cellId": "5f0eae9yldcozrwh01qp0c",
    "id": "cd7584bd"
   },
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4604183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    # Переведем текст в нижний регистр\n",
    "    text = text.lower()\n",
    "    # Разложим на токены\n",
    "    tokens = word_tokenize(text)\n",
    "    # Приведем к каждому токену часть речи\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Произведем лемматизацию в соответствии с частью речи\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(token, get_wordnet_pos(pos)) for token, pos in pos_tags\n",
    "    ]\n",
    "    # Очистим текст от цифр и знаков препинания\n",
    "    cleared_text = clear_text(\" \".join(lemmatized_tokens))\n",
    "    return cleared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1c6acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dad4b6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    clr_txt = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clr_txt_list = clr_txt.split() \n",
    "    return ' '.join(clr_txt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063e9e0",
   "metadata": {},
   "source": [
    "Произведем обработку текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd641e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097e18fbde5e4f1ea996fc24e8b48070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4326 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['lemm_text'] = train_df['query_text'].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50fff3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a man sleep under a blanket on a city street\n",
       "1    a man sleep under a blanket on a city street\n",
       "2    a man sleep under a blanket on a city street\n",
       "3    a man sleep under a blanket on a city street\n",
       "4    a man sleep under a blanket on a city street\n",
       "Name: lemm_text, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['lemm_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96eb173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим исходный стобец\n",
    "train_df = train_df.drop(['query_text'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760c0ccd",
   "metadata": {
    "cellId": "yci1zcmnsacl720fr75sb",
    "execution_id": "5ecfa9d5-3913-4fb3-a33e-99bab3798577",
    "id": "760c0ccd"
   },
   "source": [
    "## 5. Объединение векторов\n",
    "\n",
    "Подготовьте данные для обучения: объедините векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b747671f",
   "metadata": {
    "cellId": "n64cmotqegij9arvbc7sxf",
    "id": "b747671f"
   },
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    left=train_df[['image', 'query_id', 'image_embeddings', 'lemm_text']], \n",
    "    right=annotations_df[['filename', 'description_id', 'target']],\n",
    "    how='inner',\n",
    "    left_on=['image', 'query_id'],\n",
    "    right_on=['filename', 'description_id'],\n",
    ")[['image', 'image_embeddings', 'lemm_text', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2fbca724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4312 entries, 0 to 4311\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image             4312 non-null   object \n",
      " 1   image_embeddings  4312 non-null   object \n",
      " 2   lemm_text         4312 non-null   object \n",
      " 3   target            4312 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 168.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_embeddings</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[tensor(1.4565), tensor(1.4630), tensor(0.0038...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>[tensor(2.4619), tensor(5.0047), tensor(5.3163...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>[tensor(0.1198), tensor(1.9786), tensor(2.7893...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1056338697_4f7d7ce270.jpg   \n",
       "1  3187395715_f2940c2b72.jpg   \n",
       "2   463978865_c87c6ca84c.jpg   \n",
       "3   488590040_35a3e96c89.jpg   \n",
       "4   534875358_6ea30d3091.jpg   \n",
       "\n",
       "                                    image_embeddings  \\\n",
       "0  [tensor(1.4565), tensor(1.4630), tensor(0.0038...   \n",
       "1  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "2  [tensor(2.4619), tensor(5.0047), tensor(5.3163...   \n",
       "3  [tensor(0.1198), tensor(1.9786), tensor(2.7893...   \n",
       "4  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "\n",
       "                                      lemm_text    target  \n",
       "0  a man sleep under a blanket on a city street  0.111111  \n",
       "1  a man sleep under a blanket on a city street  0.222222  \n",
       "2  a man sleep under a blanket on a city street  0.200000  \n",
       "3  a man sleep under a blanket on a city street  0.222222  \n",
       "4  a man sleep under a blanket on a city street  0.111111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "primary_information(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a723a8ad",
   "metadata": {
    "cellId": "v1ntb27jt4z9fazi1y8me",
    "id": "a723a8ad"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['image']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e60d7449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3052 entries, 0 to 4311\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image             3052 non-null   object \n",
      " 1   image_embeddings  3052 non-null   object \n",
      " 2   lemm_text         3052 non-null   object \n",
      " 3   target            3052 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 119.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_embeddings</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[tensor(1.4565), tensor(1.4630), tensor(0.0038...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>[tensor(2.4619), tensor(5.0047), tensor(5.3163...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>[tensor(0.1198), tensor(1.9786), tensor(2.7893...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1056338697_4f7d7ce270.jpg   \n",
       "1  3187395715_f2940c2b72.jpg   \n",
       "2   463978865_c87c6ca84c.jpg   \n",
       "3   488590040_35a3e96c89.jpg   \n",
       "4   534875358_6ea30d3091.jpg   \n",
       "\n",
       "                                    image_embeddings  \\\n",
       "0  [tensor(1.4565), tensor(1.4630), tensor(0.0038...   \n",
       "1  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "2  [tensor(2.4619), tensor(5.0047), tensor(5.3163...   \n",
       "3  [tensor(0.1198), tensor(1.9786), tensor(2.7893...   \n",
       "4  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "\n",
       "                                      lemm_text    target  \n",
       "0  a man sleep under a blanket on a city street  0.111111  \n",
       "1  a man sleep under a blanket on a city street  0.222222  \n",
       "2  a man sleep under a blanket on a city street  0.200000  \n",
       "3  a man sleep under a blanket on a city street  0.222222  \n",
       "4  a man sleep under a blanket on a city street  0.111111  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1260 entries, 10 to 4310\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image             1260 non-null   object \n",
      " 1   image_embeddings  1260 non-null   object \n",
      " 2   lemm_text         1260 non-null   object \n",
      " 3   target            1260 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 49.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_embeddings</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1962729184_6996e128e7.jpg</td>\n",
       "      <td>[tensor(0.6466), tensor(1.3740), tensor(1.5152...</td>\n",
       "      <td>chinese market street in the winter time</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3630332976_fdba22c50b.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.7903), tenso...</td>\n",
       "      <td>a soccer ball be above the head of a man wear ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>132489044_3be606baf7.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man and woman look back at the camera while ...</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2575647360_f5de38c751.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man and woman look back at the camera while ...</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3115174046_9e96b9ce47.jpg</td>\n",
       "      <td>[tensor(2.7309), tensor(2.7041), tensor(0.), t...</td>\n",
       "      <td>a man and woman look back at the camera while ...</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        image  \\\n",
       "10  1962729184_6996e128e7.jpg   \n",
       "21  3630332976_fdba22c50b.jpg   \n",
       "24   132489044_3be606baf7.jpg   \n",
       "25  2575647360_f5de38c751.jpg   \n",
       "28  3115174046_9e96b9ce47.jpg   \n",
       "\n",
       "                                     image_embeddings  \\\n",
       "10  [tensor(0.6466), tensor(1.3740), tensor(1.5152...   \n",
       "21  [tensor(0.), tensor(0.), tensor(0.7903), tenso...   \n",
       "24  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "25  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "28  [tensor(2.7309), tensor(2.7041), tensor(0.), t...   \n",
       "\n",
       "                                            lemm_text    target  \n",
       "10           chinese market street in the winter time  0.200000  \n",
       "21  a soccer ball be above the head of a man wear ...  0.000000  \n",
       "24  a man and woman look back at the camera while ...  0.066667  \n",
       "25  a man and woman look back at the camera while ...  0.111111  \n",
       "28  a man and woman look back at the camera while ...  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "primary_information(train_df)\n",
    "primary_information(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e731772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/iuser24/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = list(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bdfc4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "train_tf_idf = count_tf_idf.fit_transform(train_df['lemm_text'].values.astype('U'))\n",
    "test_tf_idf = count_tf_idf.transform(test_df['lemm_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0c71b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы train_tf_idf: (3052, 946)\n",
      "Размер матрицы test_tf_idf: (1260, 946)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы train_tf_idf:\", train_tf_idf.shape)\n",
    "print(\"Размер матрицы test_tf_idf:\", test_tf_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "672f87a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "919     [tensor(0.4407), tensor(0.), tensor(0.), tenso...\n",
       "3355    [tensor(0.), tensor(0.), tensor(0.), tensor(0....\n",
       "507     [tensor(0.), tensor(0.0813), tensor(0.), tenso...\n",
       "102     [tensor(0.8153), tensor(1.1759), tensor(0.), t...\n",
       "2196    [tensor(0.), tensor(0.), tensor(0.), tensor(0....\n",
       "2241    [tensor(0.), tensor(0.), tensor(0.), tensor(0....\n",
       "704     [tensor(1.0943), tensor(1.8323), tensor(1.3910...\n",
       "1366    [tensor(0.), tensor(0.), tensor(0.), tensor(0....\n",
       "3397    [tensor(0.), tensor(0.), tensor(1.1576), tenso...\n",
       "2063    [tensor(0.1078), tensor(0.3590), tensor(0.), t...\n",
       "Name: image_embeddings, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)['image_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b58b75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_idf.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d3f27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "train_df['tf_idf'] = count_tf_idf.fit_transform(train_df['lemm_text'].values.astype('U'))\n",
    "test_df['tf_idf'] = count_tf_idf.transform(test_df['lemm_text'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9efce19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3052 entries, 0 to 4311\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   image             3052 non-null   object \n",
      " 1   image_embeddings  3052 non-null   object \n",
      " 2   lemm_text         3052 non-null   object \n",
      " 3   target            3052 non-null   float64\n",
      " 4   tf_idf            3052 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 143.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>image_embeddings</th>\n",
       "      <th>lemm_text</th>\n",
       "      <th>target</th>\n",
       "      <th>tf_idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>[tensor(1.4565), tensor(1.4630), tensor(0.0038...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>(0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>(0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>[tensor(2.4619), tensor(5.0047), tensor(5.3163...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>(0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>[tensor(0.1198), tensor(1.9786), tensor(2.7893...</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>(0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>a man sleep under a blanket on a city street</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>(0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image  \\\n",
       "0  1056338697_4f7d7ce270.jpg   \n",
       "1  3187395715_f2940c2b72.jpg   \n",
       "2   463978865_c87c6ca84c.jpg   \n",
       "3   488590040_35a3e96c89.jpg   \n",
       "4   534875358_6ea30d3091.jpg   \n",
       "\n",
       "                                    image_embeddings  \\\n",
       "0  [tensor(1.4565), tensor(1.4630), tensor(0.0038...   \n",
       "1  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "2  [tensor(2.4619), tensor(5.0047), tensor(5.3163...   \n",
       "3  [tensor(0.1198), tensor(1.9786), tensor(2.7893...   \n",
       "4  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "\n",
       "                                      lemm_text    target  \\\n",
       "0  a man sleep under a blanket on a city street  0.111111   \n",
       "1  a man sleep under a blanket on a city street  0.222222   \n",
       "2  a man sleep under a blanket on a city street  0.200000   \n",
       "3  a man sleep under a blanket on a city street  0.222222   \n",
       "4  a man sleep under a blanket on a city street  0.111111   \n",
       "\n",
       "                                              tf_idf  \n",
       "0    (0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...  \n",
       "1    (0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...  \n",
       "2    (0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...  \n",
       "3    (0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...  \n",
       "4    (0, 796)\\t0.34212182894483933\\n  (0, 143)\\t0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "primary_information(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bc5668",
   "metadata": {
    "cellId": "97c9jj3s2zjj62vznivsk",
    "execution_id": "1a2d7233-0c79-479a-be63-5787145e3b48",
    "id": "60bc5668"
   },
   "source": [
    "## 6. Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n",
    "Для того чтобы учесть изображения при разбиении, можно воспользоваться классом [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) из библиотеки sklearn.model_selection.\n",
    "\n",
    "Код ниже разбивает датасет на тренировочную и тестовую выборки в пропорции 7:3 так, что строки с одинаковым значением 'group_column' будут содержаться либо в тестовом, либо в тренировочном датасете.\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['group_column']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "```\n",
    "\n",
    "Какую модель использовать — выберите самостоятельно. Также вам предстоит выбрать метрику качества либо реализовать свою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8961a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f339f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_final = Pipeline([\n",
    "    ('models', LogisticRegression(random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc8cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    # словарь для модели LogisticRegression()\n",
    "    {\n",
    "        'models': [LogisticRegression(random_state=RANDOM_STATE)],\n",
    "        'models__C': [5, 10, 15],\n",
    "    },\n",
    "    # словарь для модели LGBMClassifier()\n",
    "    {\n",
    "        'models': [lgb.LGBMClassifier()]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchcv = GridSearchCV(\n",
    "    pipe_final, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "searchcv.fit(train_df[['tf_idf', 'image_embeddings']], train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd41f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_df.drop(['target', 'image_embeddings'], axis=1), train_df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f870d77",
   "metadata": {
    "cellId": "tbnfwg686jpxjdsw7cqbl",
    "execution_id": "5e14c3be-a481-438e-a979-0f4621acea44",
    "id": "2f870d77"
   },
   "source": [
    "## 7. Тестирование модели\n",
    "\n",
    "Настало время протестировать модель. Для этого получите эмбеддинги для всех тестовых изображений из папки `test_images`, выберите случайные 10 запросов из файла `test_queries.csv` и для каждого запроса выведите наиболее релевантное изображение. Сравните визуально качество поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51496e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMG_PATH = 'sp5/train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e0c32",
   "metadata": {
    "cellId": "q6sn9kh039f4a6xvu66y7",
    "id": "801e0c32"
   },
   "outputs": [],
   "source": [
    "test_queries_df = pd.read_csv(\"sp5/test_queries.csv\", sep=\"|\")\n",
    "primary_information(test_queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1345a",
   "metadata": {
    "cellId": "dnvdkzzxdpet1yc4m64cx",
    "execution_id": "3e367f6a-97e3-4ed7-9b73-39ed363fd2b7",
    "id": "fab1345a"
   },
   "source": [
    "## 8. Выводы\n",
    "\n",
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Исследовательский анализ данных выполнен\n",
    "- [ ]  Проверены экспертные оценки и краудсорсинговые оценки\n",
    "- [ ]  Из датасета исключены те объекты, которые выходят за рамки юридических ограничений\n",
    "- [ ]  Изображения векторизованы\n",
    "- [ ]  Текстовые запросы векторизованы\n",
    "- [ ]  Данные корректно разбиты на тренировочную и тестовую выборки\n",
    "- [ ]  Предложена метрика качества работы модели\n",
    "- [ ]  Предложена модель схожести изображений и текстового запроса\n",
    "- [ ]  Модель обучена\n",
    "- [ ]  По итогам обучения модели сделаны выводы\n",
    "- [ ]  Проведено тестирование работы модели\n",
    "- [ ]  По итогам тестирования визуально сравнили качество поиска"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "notebookId": "e47b60f7-b2b4-44ee-beb3-b44a93eaf068",
  "notebookPath": "precode.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
