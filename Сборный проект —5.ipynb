{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "CUQuYmMs-mKK",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CUQuYmMs-mKK",
    "tags": [
     "21a32eca-7494-4096-b202-21be1b7f0a7d"
    ]
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ff1020a",
   "metadata": {
    "cellId": "pbwq209p45adtxfy5ofecd",
    "execution_id": "7cb94123-6481-41de-973a-91abe63db303",
    "id": "1ff1020a"
   },
   "source": [
    "# Прекод\n",
    "\n",
    "# Сборный проект-5\n",
    "\n",
    "Вам поручено разработать демонстрационную версию поиска изображений по запросу.\n",
    "\n",
    "Для демонстрационной версии нужно обучить модель, которая получит векторное представление изображения, векторное представление текста, а на выходе выдаст число от 0 до 1 — покажет, насколько текст и картинка подходят друг другу.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные доступны по [ссылке](https://code.s3.yandex.net/datasets/dsplus_integrated_project_4.zip).\n",
    "\n",
    "В файле `train_dataset.csv` находится информация, необходимая для обучения: имя файла изображения, идентификатор описания и текст описания. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `train_images` содержатся изображения для тренировки модели.\n",
    "\n",
    "В файле `CrowdAnnotations.tsv` — данные по соответствию изображения и описания, полученные с помощью краудсорсинга. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "3. Доля людей, подтвердивших, что описание соответствует изображению.\n",
    "4. Количество человек, подтвердивших, что описание соответствует изображению.\n",
    "5. Количество человек, подтвердивших, что описание не соответствует изображению.\n",
    "\n",
    "В файле `ExpertAnnotations.tsv` содержатся данные по соответствию изображения и описания, полученные в результате опроса экспертов. Номера колонок и соответствующий тип данных:\n",
    "\n",
    "1. Имя файла изображения.\n",
    "2. Идентификатор описания.\n",
    "\n",
    "3, 4, 5 — оценки трёх экспертов.\n",
    "\n",
    "Эксперты ставят оценки по шкале от 1 до 4, где 1 — изображение и запрос совершенно не соответствуют друг другу, 2 — запрос содержит элементы описания изображения, но в целом запрос тексту не соответствует, 3 — запрос и текст соответствуют с точностью до некоторых деталей, 4 — запрос и текст соответствуют полностью.\n",
    "\n",
    "В файле `test_queries.csv` находится информация, необходимая для тестирования: идентификатор запроса, текст запроса и релевантное изображение. Для одной картинки может быть доступно до 5 описаний. Идентификатор описания имеет формат `<имя файла изображения>#<порядковый номер описания>`.\n",
    "\n",
    "В папке `test_images` содержатся изображения для тестирования модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2dad3c3-65ed-40ee-87fa-b756665e3cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\zhenya-pc\\anaconda3\\lib\\site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n",
      "Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.6 MB 495.5 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.6 MB 1.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.6 MB 1.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.6 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.6 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.6 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7b356cf0-4c88-4642-90e7-1569053d1632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99489b26",
   "metadata": {
    "cellId": "n6vkjcacwu39w29bfocxt",
    "execution_id": "1b731a18-3394-4b62-b3f7-018692c2d6de",
    "id": "99489b26"
   },
   "source": [
    "## 1. Исследовательский анализ данных\n",
    "\n",
    "Наш датасет содержит экспертные и краудсорсинговые оценки соответствия текста и изображения.\n",
    "\n",
    "В файле с экспертными мнениями для каждой пары изображение-текст имеются оценки от трёх специалистов. Для решения задачи вы должны эти оценки агрегировать — превратить в одну. Существует несколько способов агрегации оценок, самый простой — голосование большинства: за какую оценку проголосовала большая часть экспертов (в нашем случае 2 или 3), та оценка и ставится как итоговая. Поскольку число экспертов меньше числа классов, может случиться, что каждый эксперт поставит разные оценки, например: 1, 4, 2. В таком случае данную пару изображение-текст можно исключить из датасета.\n",
    "\n",
    "Вы можете воспользоваться другим методом агрегации оценок или придумать свой.\n",
    "\n",
    "В файле с краудсорсинговыми оценками информация расположена в таком порядке:\n",
    "\n",
    "1. Доля исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "2. Количество исполнителей, подтвердивших, что текст **соответствует** картинке.\n",
    "3. Количество исполнителей, подтвердивших, что текст **не соответствует** картинке.\n",
    "\n",
    "После анализа экспертных и краудсорсинговых оценок выберите либо одну из них, либо объедините их в одну по какому-то критерию: например, оценка эксперта принимается с коэффициентом 0.6, а крауда — с коэффициентом 0.4.\n",
    "\n",
    "Ваша модель должна возвращать на выходе вероятность соответствия изображения тексту, поэтому целевая переменная должна иметь значения от 0 до 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d946021-0965-4ca4-9012-86cd01a1d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_information(df):\n",
    "    display(df.info())\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c14a3631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   image       5822 non-null   object\n",
      " 1   query_id    5822 non-null   object\n",
      " 2   query_text  5822 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 136.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262583859_653f1469a9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2447284966_d6bbdb4b6e.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2549968784_39bfbe44f9.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2621415349_ef1a7e73be.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>A young child is wearing blue goggles and sitt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image                     query_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "1  1262583859_653f1469a9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "2  2447284966_d6bbdb4b6e.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "3  2549968784_39bfbe44f9.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "4  2621415349_ef1a7e73be.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "\n",
       "                                          query_text  \n",
       "0  A young child is wearing blue goggles and sitt...  \n",
       "1  A young child is wearing blue goggles and sitt...  \n",
       "2  A young child is wearing blue goggles and sitt...  \n",
       "3  A young child is wearing blue goggles and sitt...  \n",
       "4  A young child is wearing blue goggles and sitt...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"sp5/train_dataset.csv\")\n",
    "primary_information(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79250670",
   "metadata": {
    "cellId": "exl6m83oldxqlu1vq1s6",
    "id": "79250670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47830 entries, 0 to 47829\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   filename              47830 non-null  object \n",
      " 1   description_id        47830 non-null  object \n",
      " 2   confirmed_percentage  47830 non-null  float64\n",
      " 3   confirmed_qty         47830 non-null  int64  \n",
      " 4   disconfirmed_qty      47830 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1056338697_4f7d7ce270.jpg#2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>114051287_dd85625a04.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>1427391496_ea512cbe7f.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2073964624_52da3a0fc4.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2083434441_a93bc6306b.jpg#2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  1056338697_4f7d7ce270.jpg#2   \n",
       "1  1056338697_4f7d7ce270.jpg   114051287_dd85625a04.jpg#2   \n",
       "2  1056338697_4f7d7ce270.jpg  1427391496_ea512cbe7f.jpg#2   \n",
       "3  1056338697_4f7d7ce270.jpg  2073964624_52da3a0fc4.jpg#2   \n",
       "4  1056338697_4f7d7ce270.jpg  2083434441_a93bc6306b.jpg#2   \n",
       "\n",
       "   confirmed_percentage  confirmed_qty  disconfirmed_qty  \n",
       "0                   1.0              3                 0  \n",
       "1                   0.0              0                 3  \n",
       "2                   0.0              0                 3  \n",
       "3                   0.0              0                 3  \n",
       "4                   0.0              0                 3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crowd_df = pd.read_csv(\"sp5/CrowdAnnotations.tsv\", sep=\"\\t\", names=[\n",
    "    \"filename\", \"description_id\", \"confirmed_percentage\", \"confirmed_qty\", \"disconfirmed_qty\"\n",
    "])\n",
    "primary_information(crowd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee2a306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confirmed_percentage\n",
       "0.000000    41970\n",
       "0.333333     3000\n",
       "0.666667     1360\n",
       "1.000000     1323\n",
       "0.250000       96\n",
       "0.500000       27\n",
       "0.200000       22\n",
       "0.750000        9\n",
       "0.600000        8\n",
       "0.400000        8\n",
       "0.800000        4\n",
       "0.166667        3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crowd_df['confirmed_percentage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5136f1-37ba-41e9-81a8-c7a0e356eee7",
   "metadata": {},
   "source": [
    "Файл с краудсорсинговыми оценками содержит 47830 строк, пропущенных значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "900a0503-85a4-49a9-b815-a85157408cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5822 entries, 0 to 5821\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   filename        5822 non-null   object\n",
      " 1   description_id  5822 non-null   object\n",
      " 2   exp1            5822 non-null   int64 \n",
      " 3   exp2            5822 non-null   int64 \n",
      " 4   exp3            5822 non-null   int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 227.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3207358897_bfa61fa3c6.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3286822339_5535af6b93.jpg#2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  exp1  exp2  exp3\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2     1     1     1\n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2     1     1     2\n",
       "2  1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2     1     1     2\n",
       "3  1056338697_4f7d7ce270.jpg  3207358897_bfa61fa3c6.jpg#2     1     2     2\n",
       "4  1056338697_4f7d7ce270.jpg  3286822339_5535af6b93.jpg#2     1     1     2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expert_df = pd.read_csv(\"sp5/ExpertAnnotations.tsv\", sep=\"\\t\", names=[\n",
    "    \"filename\", \"description_id\", \"exp1\", \"exp2\", \"exp3\"\n",
    "])\n",
    "primary_information(expert_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aec0ec5-b6c4-4ccc-a9c8-5c1f3d56582a",
   "metadata": {},
   "source": [
    "Датасет содержит 5822 строки, пропущенных значений нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b444fb7-2716-4ad4-8a74-603edfc47dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2329 entries, 0 to 2328\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   filename              2329 non-null   object \n",
      " 1   description_id        2329 non-null   object \n",
      " 2   confirmed_percentage  2329 non-null   float64\n",
      " 3   confirmed_qty         2329 non-null   int64  \n",
      " 4   disconfirmed_qty      2329 non-null   int64  \n",
      " 5   exp1                  2329 non-null   int64  \n",
      " 6   exp2                  2329 non-null   int64  \n",
      " 7   exp3                  2329 non-null   int64  \n",
      "dtypes: float64(1), int64(5), object(2)\n",
      "memory usage: 145.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>434792818_56375e203f.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>256085101_2c2617c5d0.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    filename               description_id  \\\n",
       "0  1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "1  1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2   \n",
       "2  1056338697_4f7d7ce270.jpg   434792818_56375e203f.jpg#2   \n",
       "3  1082379191_ec1e53f996.jpg  1536774449_e16b1b6382.jpg#2   \n",
       "4  1084040636_97d9633581.jpg   256085101_2c2617c5d0.jpg#2   \n",
       "\n",
       "   confirmed_percentage  confirmed_qty  disconfirmed_qty  exp1  exp2  exp3  \n",
       "0              0.000000              0                 3     1     1     1  \n",
       "1              0.000000              0                 3     1     1     2  \n",
       "2              0.000000              0                 3     1     1     2  \n",
       "3              0.000000              0                 3     1     2     3  \n",
       "4              0.333333              1                 2     2     3     3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations_df = pd.merge(\n",
    "    left=crowd_df, \n",
    "    right=expert_df,\n",
    "    how='inner',\n",
    "    left_on=['filename', 'description_id'],\n",
    "    right_on=['filename', 'description_id'],\n",
    ")\n",
    "primary_information(annotations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d81118ce-f636-46aa-8fa9-9d6ea6af7e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, description_id, confirmed_percentage, confirmed_qty, disconfirmed_qty, exp1, exp2, exp3]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df[annotations_df['confirmed_percentage'].isna()|annotations_df['exp1'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab54e324-e275-411a-aeab-70a172af5e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description_id</th>\n",
       "      <th>confirmed_percentage</th>\n",
       "      <th>confirmed_qty</th>\n",
       "      <th>disconfirmed_qty</th>\n",
       "      <th>exp1</th>\n",
       "      <th>exp2</th>\n",
       "      <th>exp3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2549968784_39bfbe44f9.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>2718495608_d8533e3ac5.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>434792818_56375e203f.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1082379191_ec1e53f996.jpg</td>\n",
       "      <td>1536774449_e16b1b6382.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084040636_97d9633581.jpg</td>\n",
       "      <td>256085101_2c2617c5d0.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>3244747165_17028936e0.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>979383193_0a542a059d.jpg</td>\n",
       "      <td>3482062809_3b694322c4.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>2985679744_75a7102aab.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>3150742439_b8a352e1e0.jpg#2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>997722733_0cb5439472.jpg</td>\n",
       "      <td>486917990_72bd4069af.jpg#2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2329 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       filename               description_id  \\\n",
       "0     1056338697_4f7d7ce270.jpg  2549968784_39bfbe44f9.jpg#2   \n",
       "1     1056338697_4f7d7ce270.jpg  2718495608_d8533e3ac5.jpg#2   \n",
       "2     1056338697_4f7d7ce270.jpg   434792818_56375e203f.jpg#2   \n",
       "3     1082379191_ec1e53f996.jpg  1536774449_e16b1b6382.jpg#2   \n",
       "4     1084040636_97d9633581.jpg   256085101_2c2617c5d0.jpg#2   \n",
       "...                         ...                          ...   \n",
       "2324   979383193_0a542a059d.jpg  3244747165_17028936e0.jpg#2   \n",
       "2325   979383193_0a542a059d.jpg  3482062809_3b694322c4.jpg#2   \n",
       "2326   997722733_0cb5439472.jpg  2985679744_75a7102aab.jpg#2   \n",
       "2327   997722733_0cb5439472.jpg  3150742439_b8a352e1e0.jpg#2   \n",
       "2328   997722733_0cb5439472.jpg   486917990_72bd4069af.jpg#2   \n",
       "\n",
       "      confirmed_percentage  confirmed_qty  disconfirmed_qty  exp1  exp2  exp3  \n",
       "0                 0.000000              0                 3     1     1     1  \n",
       "1                 0.000000              0                 3     1     1     2  \n",
       "2                 0.000000              0                 3     1     1     2  \n",
       "3                 0.000000              0                 3     1     2     3  \n",
       "4                 0.333333              1                 2     2     3     3  \n",
       "...                    ...            ...               ...   ...   ...   ...  \n",
       "2324              0.000000              0                 3     2     2     2  \n",
       "2325              0.000000              0                 3     1     2     2  \n",
       "2326              0.000000              0                 3     1     1     1  \n",
       "2327              0.000000              0                 3     1     1     2  \n",
       "2328              0.333333              1                 2     3     3     3  \n",
       "\n",
       "[2329 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca9d8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_calc(x):\n",
    "    return x['confirmed_percentage'] * 0.4 + ((x['exp1'] + x['exp2'] + x['exp3']) / 3. - 1) / 3. * 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bafa304e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations_df['target'] = annotations_df.apply(target_calc, axis=1)\n",
    "annotations_df['target'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbaa861",
   "metadata": {
    "cellId": "9h91oxwx86d7i8rqt5miv4",
    "execution_id": "4401a0e8-fd2b-479b-9e84-6ffafbcead47",
    "id": "7cbaa861"
   },
   "source": [
    "## 2. Проверка данных\n",
    "\n",
    "В некоторых странах, где работает ваша компания, действуют ограничения по обработке изображений: поисковым сервисам и сервисам, предоставляющим возможность поиска, запрещено без разрешения родителей или законных представителей предоставлять любую информацию, в том числе, но не исключительно тексты, изображения, видео и аудио, содержащие описание, изображение или запись голоса детей. Ребёнком считается любой человек, не достигший 16 лет.\n",
    "\n",
    "В вашем сервисе строго следуют законам стран, в которых работают. Поэтому при попытке посмотреть изображения, запрещённые законодательством, вместо картинок показывается дисклеймер:\n",
    "\n",
    "> This image is unavailable in your country in compliance with local laws\n",
    ">\n",
    "\n",
    "Однако у вас в PoC нет возможности воспользоваться данным функционалом. Поэтому все изображения, которые нарушают данный закон, нужно удалить из обучающей выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccec4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['child', 'boy', 'girl', 'kid', 'kids', 'children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1048d565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>query_id</th>\n",
       "      <th>query_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1056338697_4f7d7ce270.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3187395715_f2940c2b72.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>463978865_c87c6ca84c.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488590040_35a3e96c89.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534875358_6ea30d3091.jpg</td>\n",
       "      <td>3181701312_70a379ab6e.jpg#2</td>\n",
       "      <td>A man sleeps under a blanket on a city street .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>799486353_f665d7b0f0.jpg</td>\n",
       "      <td>2170222061_e8bce4a32d.jpg#2</td>\n",
       "      <td>A small animal leaps behind a larger animal , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>799486353_f665d7b0f0.jpg</td>\n",
       "      <td>2196107384_361d73a170.jpg#2</td>\n",
       "      <td>a old man walks down the uncrowded road .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4388</th>\n",
       "      <td>909808296_23c427022d.jpg</td>\n",
       "      <td>2112921744_92bf706805.jpg#2</td>\n",
       "      <td>A dog stands on the side of a grassy cliff .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>929679367_ff8c7df2ee.jpg</td>\n",
       "      <td>3651971126_309e6a5e22.jpg#2</td>\n",
       "      <td>A blurry photo of two dogs .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4390</th>\n",
       "      <td>968081289_cdba83ce2e.jpg</td>\n",
       "      <td>2292406847_f366350600.jpg#2</td>\n",
       "      <td>A man rows his boat below .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4391 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image                     query_id  \\\n",
       "0     1056338697_4f7d7ce270.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "1     3187395715_f2940c2b72.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "2      463978865_c87c6ca84c.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "3      488590040_35a3e96c89.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "4      534875358_6ea30d3091.jpg  3181701312_70a379ab6e.jpg#2   \n",
       "...                         ...                          ...   \n",
       "4386   799486353_f665d7b0f0.jpg  2170222061_e8bce4a32d.jpg#2   \n",
       "4387   799486353_f665d7b0f0.jpg  2196107384_361d73a170.jpg#2   \n",
       "4388   909808296_23c427022d.jpg  2112921744_92bf706805.jpg#2   \n",
       "4389   929679367_ff8c7df2ee.jpg  3651971126_309e6a5e22.jpg#2   \n",
       "4390   968081289_cdba83ce2e.jpg  2292406847_f366350600.jpg#2   \n",
       "\n",
       "                                             query_text  \n",
       "0       A man sleeps under a blanket on a city street .  \n",
       "1       A man sleeps under a blanket on a city street .  \n",
       "2       A man sleeps under a blanket on a city street .  \n",
       "3       A man sleeps under a blanket on a city street .  \n",
       "4       A man sleeps under a blanket on a city street .  \n",
       "...                                                 ...  \n",
       "4386  A small animal leaps behind a larger animal , ...  \n",
       "4387          a old man walks down the uncrowded road .  \n",
       "4388       A dog stands on the side of a grassy cliff .  \n",
       "4389                       A blurry photo of two dogs .  \n",
       "4390                        A man rows his boat below .  \n",
       "\n",
       "[4391 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = train_df[train_df['query_text'].str.extract(f\"({'|'.join(stopwords)})\").notna()[0]].index\n",
    "train_df = train_df.drop(idx).reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352d2cd",
   "metadata": {
    "cellId": "6j23jr8qr9wgyyqkm2puj",
    "id": "b352d2cd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d4ef807",
   "metadata": {
    "cellId": "ggxcvhmhcm9rshysbjoo4n",
    "execution_id": "d7935f99-48c0-42b8-a227-dd2b2d9b70fc",
    "id": "1d4ef807"
   },
   "source": [
    "## 3. Векторизация изображений\n",
    "\n",
    "Перейдём к векторизации изображений.\n",
    "\n",
    "Самый примитивный способ — прочесть изображение и превратить полученную матрицу в вектор. Такой способ нам не подходит: длина векторов может быть сильно разной, так как размеры изображений разные. Поэтому стоит обратиться к свёрточным сетям: они позволяют \"выделить\" главные компоненты изображений. Как это сделать? Нужно выбрать какую-либо архитектуру, например ResNet-18, посмотреть на слои и исключить полносвязные слои, которые отвечают за конечное предсказание. При этом можно загрузить модель данной архитектуры, предварительно натренированную на датасете ImageNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "fb18b2e3-c8cf-4392-8663-e6ac16fc4886",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_PATH = 'sp5/train_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0167b804",
   "metadata": {
    "cellId": "4wiflhqkew9mq1gq5927e",
    "id": "0167b804"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhenya-PC\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Zhenya-PC\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True) #загружаем претренированную модель\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a8cf7fb4-f519-4a97-af82-97a49cef62c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(resnet.children())[:-2]\n",
    "resnet = nn.Sequential(*modules) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f31fbbee-5dce-4195-9dae-fbd35ba3733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a9778643-32b8-494e-9785-de9412818874",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    norm,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "258ecc2e-81a3-445a-beb9-3368119000ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"sp5/train_images/488590040_35a3e96c89.jpg\").convert('RGB')\n",
    "input_tensor = preprocess(img)\n",
    "output_tensor = resnet(input_tensor.unsqueeze(0)).flatten() # сразу спрямим тензор в вектор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "734b5378-3927-4425-b3db-271fb209916e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(x):\n",
    "    img = Image.open(f\"{TRAIN_IMG_PATH}/{x}\").convert('RGB')\n",
    "    return resnet(preprocess(img).unsqueeze(0)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2879b425-a2a8-4b43-a132-96a06c7ca7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['image_embeddings'] = train_df['image'].apply(create_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea53bf6",
   "metadata": {
    "cellId": "z8evfugfch8wpstvnxv0t",
    "execution_id": "028ade1d-49fe-4110-8b13-3c1aecdaa142",
    "id": "aea53bf6"
   },
   "source": [
    "## 4. Векторизация текстов\n",
    "\n",
    "Следующий этап — векторизация текстов. Вы можете поэкспериментировать с несколькими способами векторизации текстов:\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- \\*трансформеры (например Bert)\n",
    "\n",
    "\\* — если вы изучали трансформеры в спринте Машинное обучение для текстов.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7584bd",
   "metadata": {
    "cellId": "5f0eae9yldcozrwh01qp0c",
    "id": "cd7584bd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "760c0ccd",
   "metadata": {
    "cellId": "yci1zcmnsacl720fr75sb",
    "execution_id": "5ecfa9d5-3913-4fb3-a33e-99bab3798577",
    "id": "760c0ccd"
   },
   "source": [
    "## 5. Объединение векторов\n",
    "\n",
    "Подготовьте данные для обучения: объедините векторы изображений и векторы текстов с целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b747671f",
   "metadata": {
    "cellId": "n64cmotqegij9arvbc7sxf",
    "id": "b747671f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60bc5668",
   "metadata": {
    "cellId": "97c9jj3s2zjj62vznivsk",
    "execution_id": "1a2d7233-0c79-479a-be63-5787145e3b48",
    "id": "60bc5668"
   },
   "source": [
    "## 6. Обучение модели предсказания соответствия\n",
    "\n",
    "Для обучения разделите датасет на тренировочную и тестовую выборки. Простое случайное разбиение не подходит: нужно исключить попадание изображения и в обучающую, и в тестовую выборки.\n",
    "Для того чтобы учесть изображения при разбиении, можно воспользоваться классом [GroupShuffleSplit](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html) из библиотеки sklearn.model_selection.\n",
    "\n",
    "Код ниже разбивает датасет на тренировочную и тестовую выборки в пропорции 7:3 так, что строки с одинаковым значением 'group_column' будут содержаться либо в тестовом, либо в тренировочном датасете.\n",
    "\n",
    "```\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "gss = GroupShuffleSplit(n_splits=1, train_size=.7, random_state=42)\n",
    "train_indices, test_indices = next(gss.split(X=df.drop(columns=['target']), y=df['target'], groups=df['group_column']))\n",
    "train_df, test_df = df.loc[train_indices], df.loc[test_indices]\n",
    "\n",
    "```\n",
    "\n",
    "Какую модель использовать — выберите самостоятельно. Также вам предстоит выбрать метрику качества либо реализовать свою."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723a8ad",
   "metadata": {
    "cellId": "v1ntb27jt4z9fazi1y8me",
    "id": "a723a8ad"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f870d77",
   "metadata": {
    "cellId": "tbnfwg686jpxjdsw7cqbl",
    "execution_id": "5e14c3be-a481-438e-a979-0f4621acea44",
    "id": "2f870d77"
   },
   "source": [
    "## 7. Тестирование модели\n",
    "\n",
    "Настало время протестировать модель. Для этого получите эмбеддинги для всех тестовых изображений из папки `test_images`, выберите случайные 10 запросов из файла `test_queries.csv` и для каждого запроса выведите наиболее релевантное изображение. Сравните визуально качество поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801e0c32",
   "metadata": {
    "cellId": "q6sn9kh039f4a6xvu66y7",
    "id": "801e0c32"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fab1345a",
   "metadata": {
    "cellId": "dnvdkzzxdpet1yc4m64cx",
    "execution_id": "3e367f6a-97e3-4ed7-9b73-39ed363fd2b7",
    "id": "fab1345a"
   },
   "source": [
    "## 8. Выводы\n",
    "\n",
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Исследовательский анализ данных выполнен\n",
    "- [ ]  Проверены экспертные оценки и краудсорсинговые оценки\n",
    "- [ ]  Из датасета исключены те объекты, которые выходят за рамки юридических ограничений\n",
    "- [ ]  Изображения векторизованы\n",
    "- [ ]  Текстовые запросы векторизованы\n",
    "- [ ]  Данные корректно разбиты на тренировочную и тестовую выборки\n",
    "- [ ]  Предложена метрика качества работы модели\n",
    "- [ ]  Предложена модель схожести изображений и текстового запроса\n",
    "- [ ]  Модель обучена\n",
    "- [ ]  По итогам обучения модели сделаны выводы\n",
    "- [ ]  Проведено тестирование работы модели\n",
    "- [ ]  По итогам тестирования визуально сравнили качество поиска"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Отсутствует",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "notebookId": "e47b60f7-b2b4-44ee-beb3-b44a93eaf068",
  "notebookPath": "precode.ipynb",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
