{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f7efaca",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9eeca2",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6889cf26",
   "metadata": {},
   "source": [
    "#### Необходимо"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec562e",
   "metadata": {},
   "source": [
    "Обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении имеется набор данных с разметкой о токсичности правок.\n",
    "Построить модель со значением метрики качества F1 не меньше 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47058d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymystem3 in /home/iuser24/anaconda3/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in /home/iuser24/anaconda3/lib/python3.8/site-packages (from pymystem3) (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from requests->pymystem3) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from requests->pymystem3) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from requests->pymystem3) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/iuser24/anaconda3/lib/python3.8/site-packages (from requests->pymystem3) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534801f6",
   "metadata": {},
   "source": [
    "Подключим необхоимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f62ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import notebook\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# загружаем класс pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# импортируем класс GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# загружаем нужные модели\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8383b807",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/iuser24/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/iuser24/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/iuser24/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/iuser24/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d2972b",
   "metadata": {},
   "source": [
    "Загрузим датасет с комметариями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de7e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9e224a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89e1d8",
   "metadata": {},
   "source": [
    "Датасет содержит 159292 записей комментариев с пометкой токсичности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f2c476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de46f3",
   "metadata": {},
   "source": [
    "Язык комментариев - английский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10a4059",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b8c68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    # Переведем текст в нижний регистр\n",
    "    text = text.lower()\n",
    "    # Разложим на токены\n",
    "    tokens = word_tokenize(text)\n",
    "    # Приведем к каждому токену часть речи\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    # Произведем лемматизацию в соответствии с частью речи\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(token, get_wordnet_pos(pos)) for token, pos in pos_tags\n",
    "    ]\n",
    "    # Очистим текст от цифр и знаков препинания\n",
    "    cleared_text = clear_text(\" \".join(lemmatized_tokens))\n",
    "    return cleared_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fa07c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "146accb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    clr_txt = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    clr_txt_list = clr_txt.split() \n",
    "    return ' '.join(clr_txt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8c046a",
   "metadata": {},
   "source": [
    "Произведем обработку текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7908bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemm_text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f00a01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим исходный стобец\n",
    "df = df.drop(['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d75032c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/iuser24/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = list(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df3ab91",
   "metadata": {},
   "source": [
    "Разделим датасет на тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ab37501",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29dbc0",
   "metadata": {},
   "source": [
    "Векторизируем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c53040c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "tf_idf_train = count_tf_idf.fit_transform(train['lemm_text'])\n",
    "tf_idf_test = count_tf_idf.transform(test['lemm_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da1aca4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы train: (143362, 148617)\n",
      "Размер матрицы test: (15930, 148617)\n"
     ]
    }
   ],
   "source": [
    "print(\"Размер матрицы train:\", tf_idf_train.shape)\n",
    "print(\"Размер матрицы test:\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce8fb8f",
   "metadata": {},
   "source": [
    "Создадим пайплайн для обучения двух моделей: Логистическая регрессия и Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1a9ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "463a0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_final = Pipeline([\n",
    "    ('models', LogisticRegression(random_state=RANDOM_STATE))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36fcff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'models': [\n",
    "            LogisticRegression(random_state=RANDOM_STATE),\n",
    "            lgb.LGBMClassifier()\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e9f8c",
   "metadata": {},
   "source": [
    "Запустим обучение и поиск лучшей модели. В качестве метрики выберем Accuracy. Она покажет нам сколько правильных предсказаний сделала модель относительно общего числа предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a77e0d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 14530, number of negative: 128832\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 11.725938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 594330\n",
      "[LightGBM] [Info] Number of data points in the train set: 143362, number of used features: 10936\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.101352 -> initscore=-2.182294\n",
      "[LightGBM] [Info] Start training from score -2.182294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;models&#x27;,\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;models&#x27;: [LogisticRegression(random_state=42),\n",
       "                                     LGBMClassifier()]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;models&#x27;,\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;models&#x27;: [LogisticRegression(random_state=42),\n",
       "                                     LGBMClassifier()]}],\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;models&#x27;, LogisticRegression(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('models',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'models': [LogisticRegression(random_state=42),\n",
       "                                     LGBMClassifier()]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchcv = GridSearchCV(\n",
    "    pipe_final, \n",
    "    param_grid, \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "searchcv.fit(tf_idf_train, train['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d0a3021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшая модель и её параметры:\n",
      "\n",
      " Pipeline(steps=[('models', LGBMClassifier())])\n",
      "Метрика лучшей модели на тренировочной выборке: 0.9556925839091249\n"
     ]
    }
   ],
   "source": [
    "print('Лучшая модель и её параметры:\\n\\n', searchcv.best_estimator_)\n",
    "print ('Метрика лучшей модели на тренировочной выборке:', searchcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96f7b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = searchcv.best_estimator_.named_steps['models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9e3d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_pred = best_model.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a531dd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность предсказаний на тестовой выборке составляет: 0.9531701192718142\n"
     ]
    }
   ],
   "source": [
    "print('Точность предсказаний на тестовой выборке составляет:', accuracy_score(test['toxic'], toxic_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d737b502",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "В ходе работы 159292 записей комментариев с пометкой токсичности. Комментарии были обработаны. Обработка заключала в себе следующие шаги:\n",
    "\n",
    "- Перевод текста в нижний регистр\n",
    "- Лемматизация в соответствии с частью речи\n",
    "- Очистка текста от цифр и знаков препинания\n",
    "\n",
    "Далее текст был векторизирован и разделен на тренировочную и тестовую выборки. Модели для обучения были выбраны логистическая регрессия и градиентный бустинг. В качестве метрики выбран Accuracy. Данная метрика показала нам сколько правильных предсказаний сделала модель относительно общего числа предсказаний. В результате обучения была наилучшие результаты показала модель градиентного бустинга. Результат у лучшей модели на тестовой выборкесоставил 95%. Это говорит о том, что модель в 95-ти случаях из 100 успешно определяет токсичный комментарий."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
